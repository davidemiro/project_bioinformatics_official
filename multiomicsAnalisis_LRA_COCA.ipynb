{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-omics analisis with LRA cluster and COCA\n",
    "\n",
    "* [Load data and preprocessing](#Load-data-and-preprocessing)\n",
    "* [Dataset alignment](#Dataset-alignment)\n",
    "* [LRA cluster](#LRA-cluster)\n",
    "    * [LRA cluster R implementation](#LRA-cluster-R-implementation)\n",
    "    * [LRA cluster python implementation](#LRA-cluster-python-implementation)\n",
    "* [Clinic Data](#Clinic-Data)\n",
    "* [COCA](#COCA)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import r\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from myclass.CleanMergeDataset import Clean_Merge_Dataset\n",
    "from myclass.BonferroniTtest import Bonferroni_Ttest\n",
    "#import plotly.express as px\n",
    "from sklearn.cluster import DBSCAN, KMeans, AgglomerativeClustering, SpectralClustering\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#reload(myclass.BonferroniTtest)\n",
    "#reload(myclass.CleanMergeDataset)\n",
    "from rpy2.robjects.packages import STAP\n",
    "import rpy2.robjects as robjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and preprocessing\n",
    "\n",
    "Loading the datasets, clean them through class *Clean_Merge_Dataset*, reduce the number of features with *Bonferroni_Ttest*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_normal = pd.read_pickle('./SimilarityNetworkFusion/data-ready/miRNA_dataframe_normal').replace('/', '\\\\')\n",
    "data_tumor = pd.read_pickle('./SimilarityNetworkFusion/data-ready/miRNA_dataframe').replace('/', '\\\\')\n",
    "df_miRNA, y_miRNA = Clean_Merge_Dataset(name='miRNA').transform(data_normal, data_tumor)\n",
    "\n",
    "data_normal = pd.read_pickle('./SimilarityNetworkFusion/data-ready/RNA_dataframe_normal').replace('/', '\\\\')\n",
    "data_tumor = pd.read_pickle('./SimilarityNetworkFusion/data-ready/RNA_dataframe').replace('/', '\\\\')\n",
    "df_RNA, y_RNA = Clean_Merge_Dataset(name='RNA').transform(data_normal, data_tumor)\n",
    "\n",
    "\n",
    "data_normal = pd.read_pickle('./SimilarityNetworkFusion/data-ready/illumina-27-450-normal').replace('/', '\\\\')\n",
    "data_tumor = pd.read_pickle('./SimilarityNetworkFusion/data-ready/illumina450-27-tumor').replace('/', '\\\\')\n",
    "df_illumina, y_illumina= Clean_Merge_Dataset(name='illumina').transform(data_normal, data_tumor)\n",
    "\n",
    "dataset_RNA = Bonferroni_Ttest(label_case_id_into_X=True, alpha=0.05).fit_transform(df_RNA, y_RNA)\n",
    "dataset_miRNA_m = Bonferroni_Ttest(label_case_id_into_X=True, alpha=0.05).fit_transform(df_miRNA, y_miRNA)\n",
    "dataset_illumina = Bonferroni_Ttest(label_case_id_into_X=True, alpha=0.05).fit_transform(df_illumina, y_illumina)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data aligment\n",
    "\n",
    "In this section we eliminate all the examples that are not present in all 3 omics. We noticed that there are samples with the same case id but with different labels. We decided to use them for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueCaseID(data):\n",
    "    new = {}\n",
    "    new[\"case_id1\"] = []\n",
    "    data = data.copy()\n",
    "\n",
    "    data  = data[data[\"label\"] != \"CPTAC-3\"]\n",
    "    \n",
    "    data = data.sort_values(by=['case_id']).reset_index(drop=True)\n",
    "    for i,row in data.iterrows():\n",
    "        new[\"case_id1\"].append(data.loc[i,\"case_id\"]+\"_\"+str(data.loc[i,'label']))\n",
    "   \n",
    "    new_df = pd.DataFrame(new, columns = [\"case_id1\"])\n",
    "    conc_df = pd.concat([new_df,data], axis=1)\n",
    "    conc_df = conc_df.drop([\"case_id\"], axis=1)\n",
    "    \n",
    "    return conc_df\n",
    "\n",
    "\n",
    "\n",
    "illu = uniqueCaseID(dataset_illumina[0])\n",
    "rna = uniqueCaseID(dataset_RNA[0])\n",
    "mirna = uniqueCaseID(dataset_miRNA_m[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i1 = set(illu['case_id1'])\n",
    "i2 = set(mirna['case_id1'])\n",
    "i3 = set(rna['case_id1'])\n",
    "\n",
    "#Prendiamo i case_id_label che stanno in tutti e 3 le omiche\n",
    "distinct_case_id = [x for x in i2 if x in i1 and x in i3]\n",
    "\n",
    "\n",
    "#print(distinct_case_id)\n",
    "#Filtriamo i case_id_label che non stanno in tutte e 3 le omiche\n",
    "illu = illu.loc[illu['case_id1'].isin(distinct_case_id)]\n",
    "rna = rna.loc[rna['case_id1'].isin(distinct_case_id)]\n",
    "mirna = mirna.loc[mirna['case_id1'].isin(distinct_case_id)]\n",
    "\n",
    "illu = illu.sort_values(by=['case_id1']).reset_index(drop=True)\n",
    "rna = rna.sort_values(by=['case_id1']).reset_index(drop=True)\n",
    "mirna = mirna.sort_values(by=['case_id1']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "label = illu['label']\n",
    "label[label == False] ='False'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRA cluster\n",
    "\n",
    "In the following two sections we analyze the LRA cluster algorithm, an example of early multi-omics integration. We have re-implemented this algorithm in python, trying to improve its efficiency by eliminating some superfluous operations or re-implementing them using more efficient python libraries such as jax.LRA clsuter extract features that can be usefull for a clustering algorithm.We tested it with the **Agglomerative clustering, Spectral clustering and KMeans algorithms**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRA cluster R implementation\n",
    "\n",
    "In this section we run the official R implementation of LRA cluster.We run the R code by using the rpy2 library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "  r_illu_d = ro.conversion.py2rpy(illu.drop([\"case_id1\",\"label\"], axis=1))\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "  r_miRNA_d = ro.conversion.py2rpy(mirna.drop([\"case_id1\",\"label\"], axis=1))\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "  r_rna_d = ro.conversion.py2rpy(rna.drop([\"case_id1\",\"label\"], axis=1))\n",
    "\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import SignatureTranslatedAnonymousPackage\n",
    "\n",
    "\n",
    "##LRA cluster R\n",
    "file_LRA_cluster = open(\"LRAcluster/R/LRAcluster.R\",'r')\n",
    "\n",
    "string_LRA_cluster = ''.join(file_LRA_cluster.readlines())\n",
    "\n",
    "LRA_cluster = SignatureTranslatedAnonymousPackage(string_LRA_cluster, \"LRAcluster\")\n",
    "\n",
    "#Trasformiamo in matrici i 3 dataset\n",
    "matrix_r_miRNA_d = LRA_cluster.getMatrix(r_miRNA_d)\n",
    "matrix_r_illu_d = LRA_cluster.getMatrix(r_illu_d)\n",
    "matrix_r_rna_d = LRA_cluster.getMatrix(r_rna_d)\n",
    "\n",
    "#Uniamo le matrici --> data\n",
    "import time;\n",
    "\n",
    "unionMatrix = LRA_cluster.unionMatrix3(matrix_r_illu_d, matrix_r_rna_d, matrix_r_miRNA_d)\n",
    "start_time = time.time()\n",
    "output_R = LRA_cluster.LRAcluster(unionMatrix,3)\n",
    "print(start_time - time.time())\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    output = ro.conversion.rpy2py(output_R[0])\n",
    "\n",
    "clustering = KMeans(n_clusters=3, max_iter=500).fit(output)\n",
    "clustering1 = AgglomerativeClustering(n_clusters=3, linkage='ward').fit(output)\n",
    "clustering2 = SpectralClustering(n_clusters=3, assign_labels='discretize').fit(output)\n",
    "\n",
    "\n",
    "print(\"KMEANS\")\n",
    "print(\"silhuette: \", silhouette_score(output, clustering.labels_))\n",
    "print(\"rand indexa: \", adjusted_rand_score(label, clustering.labels_))\n",
    "print(\"AGGLOMERATIVE CLUSTERING\")\n",
    "print(\"silhuette: \", silhouette_score(output, clustering1.labels_))\n",
    "print(\"rand indexa: \", adjusted_rand_score(label, clustering1.labels_))\n",
    "print(\"SPECTRAL CLUSTERING\")\n",
    "print(\"silhuette: \", silhouette_score(output, clustering2.labels_))\n",
    "print(\"rand indexa: \", adjusted_rand_score(label, clustering2.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRA cluster python implementation\n",
    "\n",
    "In this section we perform our python implementation of the LRA cluster algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#LRA cluster python implementation\n",
    "label = illu['label']\n",
    "label[label == False] ='False'\n",
    "\n",
    "from PyLRAcluster.LRACluster import LRAcluster\n",
    "import time\n",
    "\n",
    "\n",
    "illu_m = np.transpose(illu.drop([\"case_id1\",\"label\"], axis=1).to_numpy())\n",
    "rna_m = np.transpose(rna.drop([\"case_id1\",\"label\"], axis=1).to_numpy())\n",
    "mirna_m = np.transpose(mirna.drop([\"case_id1\",\"label\"], axis=1).to_numpy())\n",
    "\n",
    "start_time = time.time()\n",
    "output,p = LRAcluster([illu_m,rna_m,mirna_m],['gaussian','poisson','poisson'],3)\n",
    "print(start_time - time.time())\n",
    "\n",
    "clustering = KMeans(n_clusters=3, max_iter=500).fit(output)\n",
    "clustering1 = AgglomerativeClustering(n_clusters=3, linkage='ward').fit(output)\n",
    "clustering2 = SpectralClustering(n_clusters=3, assign_labels='discretize').fit(output)\n",
    "\n",
    "\n",
    "print(\"KMEANS\")\n",
    "print(\"silhuette: \", silhouette_score(output, clustering.labels_))\n",
    "print(\"rand indexa: \", adjusted_rand_score(label, clustering.labels_))\n",
    "print(\"AGGLOMERATIVE CLUSTERING\")\n",
    "print(\"silhuette: \", silhouette_score(output, clustering1.labels_))\n",
    "print(\"rand indexa: \", adjusted_rand_score(label, clustering1.labels_))\n",
    "print(\"SPECTRAL CLUSTERING\")\n",
    "print(\"silhuette: \", silhouette_score(output, clustering2.labels_))\n",
    "print(\"rand indexa: \", adjusted_rand_score(label, clustering2.labels_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot graph##\n",
    "le = LabelEncoder()\n",
    "labels_num = le.fit_transform(clustering2.labels_)\n",
    "plt.figure('LRA 3 dimension Spectral clustering', figsize=(15,15))\n",
    "ax = plt.axes(projection = '3d')\n",
    "ax.legend()\n",
    "ax.scatter(output[:,0],output[:,1],output[:,2],c=labels_num);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinic Data\n",
    "\n",
    "We want to apply the information retrieved from clinical-data to the results obtained by the best clustering  (Spectral clustering). The link between the datas is the case_id. The fields chosen from clinical-data's file are:\n",
    "- tumor_stage: stage of tumor.\n",
    "- prior_malignancy: precedent diagnosys of tumors.\n",
    "- age_at_diagnosis: patient's age which is diagnosed the tumor. We have considered only the year's decades.\n",
    "- morphology: kind of tumor, which is identified from a code id.\n",
    "- cigarettes per day: the average number of cigarettes smoked by the patient in one day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATI CLINICI\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\"\"\"\n",
    "    Class to extract the clinical_case from the json file.\n",
    "    It returns a dataframe in the following form:\n",
    "    case_id| ...[clinical case]...| label.\n",
    "\"\"\"\n",
    "#set the cluster predicted labels as the labels predicted by Spectral clustering\n",
    "y_pred = clustering2.labels_\n",
    "\n",
    "#Class used to extract clinical data from the json file.\n",
    "class ExtractClinicalCase:\n",
    "    def __init__(self, cases_id):\n",
    "        with open('./SimilarityNetworkFusion/data-ready/clinical.cases_selection.2020-11-12.json', 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "\n",
    "        remove_el = list()\n",
    "        for el in data:\n",
    "            if el['case_id'] not in cases_id:\n",
    "                remove_el.append(el)\n",
    "\n",
    "        for el in remove_el:\n",
    "            data.remove(el)\n",
    "        \n",
    "        clinical_data = {'case_id': '',\n",
    "                        'tumor_stage': '',\n",
    "                        'prior_malignancy': '',\n",
    "                        'age_at_diagnosis': None,\n",
    "                        'morphology': '',\n",
    "                        'label': ''}\n",
    "\n",
    "        self.df = pd.DataFrame(data=[], columns=clinical_data.keys())\n",
    "\n",
    "        for i, el in enumerate(data):\n",
    "            clinical_data['case_id'] = el['case_id']\n",
    "            clinical_data['tumor_stage'] = el['diagnoses'][0]['tumor_stage']\n",
    "            clinical_data['prior_malignancy'] = el['diagnoses'][0]['prior_malignancy']\n",
    "            if el['diagnoses'][0]['age_at_diagnosis'] is not None:\n",
    "                value = int(el['diagnoses'][0]['age_at_diagnosis'])/365\n",
    "                clinical_data['age_at_diagnosis'] = self.__truncate__(value)\n",
    "\n",
    "            clinical_data['morphology'] = el['diagnoses'][0]['morphology']\n",
    "            if el['exposures'][0]['cigarettes_per_day'] is not None:\n",
    "                value = int(el['exposures'][0]['cigarettes_per_day'])\n",
    "                clinical_data['cigarettes_per_day'] = value\n",
    "\n",
    "            self.df = self.df.append(pd.DataFrame(clinical_data, index=[i]), ignore_index=True)\n",
    "        \n",
    "    def get_df_clinical_case(self):\n",
    "        return self.df\n",
    "\n",
    "    def __truncate__(self, n, decimals=-1):\n",
    "        \"\"\"\n",
    "            Function to take the decade of the age.\n",
    "        \"\"\"\n",
    "        multiplier = 10 ** decimals\n",
    "        return int(n * multiplier) / multiplier\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "cases_id = [el.split('_')[0] for el in rna['case_id1']]\n",
    "df_clinical_case = ExtractClinicalCase(cases_id).get_df_clinical_case()\n",
    "\n",
    "df_clinical_case.sort_values(by='case_id', inplace=True)\n",
    "df = pd.DataFrame()\n",
    "df['case_id'] = cases_id\n",
    "df['label'] = y_pred\n",
    "clinica_cases_id = [el.replace('\\n', '') for el in df_clinical_case['case_id']]\n",
    "\n",
    "label = df.loc[df['case_id'].isin(clinica_cases_id)]['label']\n",
    "df_clinical_case['label'] = label\n",
    "\n",
    "\n",
    "#Function to plot clinical data \n",
    "def plot_clinical_data(df_clinical_case, name_clinical_field, title=''):\n",
    "    dict_ = {}\n",
    "    df = pd.DataFrame()\n",
    "    df_clinical_case.dropna(inplace=True)\n",
    "\n",
    "\n",
    "    for l in range(0, 3):\n",
    "        dict_['Cluster'] = l\n",
    "        for el in set(df_clinical_case[name_clinical_field]):\n",
    "            el_cluster = df_clinical_case[df_clinical_case['label'] == l]\n",
    "            count = el_cluster[el_cluster[name_clinical_field] == el]['case_id'].count()\n",
    "            dict_[el] = count\n",
    "\n",
    "        df = df.append(pd.DataFrame(dict_, index=[0]))\n",
    "\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for key in df.columns[1:]:\n",
    "        fig = fig.add_trace(\n",
    "            go.Bar(name=key, x=df['Cluster'], y=df[key])\n",
    "        )\n",
    "    \n",
    "    # Change the bar mode\n",
    "    fig.update_layout(barmode='stack',\n",
    "                      title=title,\n",
    "                      xaxis_title=\"Clusters\",\n",
    "                      yaxis_title=\"Count\")\n",
    "    fig.show() \n",
    "    return\n",
    "\n",
    " \n",
    "plot_clinical_data(df_clinical_case, 'prior_malignancy', 'Prior Malignancy Distribution')\n",
    "plot_clinical_data(df_clinical_case, 'age_at_diagnosis', 'Age at diagnosis Distribution')\n",
    "plot_clinical_data(df_clinical_case, 'tumor_stage', 'Tumor stage Distribution')\n",
    "plot_clinical_data(df_clinical_case, 'morphology', 'Morphology Distribution')\n",
    "plot_clinical_data(df_clinical_case, 'cigarettes_per_day', 'Cigarettes per day Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCA \n",
    "\n",
    "In this section we have implemented the cluster of clusters algorithm (COCA). This algorithm was performed on the best combinations of preprocessing and algorithms that emerged from the single omic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Clustering a singola omica\n",
    "def vectorIndicator(indicator_vector_matrix,labels):\n",
    "    new_encodings = []\n",
    "    for i in range(labels.shape[0]):\n",
    "        label_encoding = [0,0,0]\n",
    "        label_encoding[labels[i]] = 1 # 0 -> [1,0,0] 1 ->[0,1,0] 2->[0,0,1]\n",
    "        new_encodings.append(label_encoding)\n",
    "    if indicator_vector_matrix.shape[0] == 0:\n",
    "        indicator_vector_matrix = np.array(new_encodings)\n",
    "    else:\n",
    "        indicator_vector_matrix = np.concatenate((indicator_vector_matrix,np.array(new_encodings)),axis=1)\n",
    "    return indicator_vector_matrix\n",
    "\n",
    "def compute_vector_indicator(*args):\n",
    "    indicator_vector_matrix = np.array([])\n",
    "    for a in args:\n",
    "        indicator_vector_matrix = vectorIndicator(indicator_vector_matrix,a.labels_)\n",
    "    return indicator_vector_matrix\n",
    "\n",
    "\n",
    "illu_new = uniqueCaseID(df_illumina)\n",
    "mirna_new =uniqueCaseID(df_miRNA)\n",
    "rna_new = uniqueCaseID(df_RNA)\n",
    "\n",
    "i1 = set(illu_new['case_id1'])\n",
    "i2 = set(mirna_new['case_id1'])\n",
    "i3 = set(rna_new['case_id1'])\n",
    "\n",
    "#Prendiamo i case_id_label che stanno in tutti e 3 le omiche\n",
    "distinct_case_id = [x for x in i2 if x in i1 and x in i3]\n",
    "\n",
    "\n",
    "#print(distinct_case_id)\n",
    "#Filtriamo i case_id_label che non stanno in tutte e 3 le omiche\n",
    "illu_new = illu_new.loc[illu_new['case_id1'].isin(distinct_case_id)]\n",
    "rna_new = rna_new.loc[rna_new['case_id1'].isin(distinct_case_id)]\n",
    "mirna_new = mirna_new.loc[mirna_new['case_id1'].isin(distinct_case_id)]\n",
    "\n",
    "illu_new = illu_new.sort_values(by=['case_id1']).reset_index(drop=True)\n",
    "rna_new = rna_new.sort_values(by=['case_id1']).reset_index(drop=True)\n",
    "mirna_new = mirna_new.sort_values(by=['case_id1']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "label = illu_new['label']\n",
    "label[label == False] = 'False'\n",
    "\n",
    "#No bonferroni\n",
    "illu_new = illu_new.drop(['case_id1','label'],axis=1)\n",
    "mirna_new = mirna_new.drop(['case_id1','label'],axis=1)\n",
    "rna_new = rna_new.drop(['case_id1','label'],axis=1)\n",
    "\n",
    "#With bonferroni\n",
    "illu_r = illu.drop(['case_id1','label'],axis=1)\n",
    "mirna_r = mirna.drop(['case_id1','label'],axis=1)\n",
    "rna_r = rna.drop(['case_id1','label'],axis=1)\n",
    "\n",
    "SEED = 9\n",
    "#mirna->Bonferroni->Maxminscaler->PCA->Spectral cluestering\n",
    "pipe = Pipeline([('min_max_scale', MinMaxScaler()),('pca', PCA(0.9)),('spectral_clustering',SpectralClustering(n_clusters=3, assign_labels='discretize'))])\n",
    "c1 = pipe.fit(mirna_r)[-1]\n",
    "#mirna->Bonferroni->Maxminscaler->PCA->Spectral cluestering\n",
    "pipe = Pipeline([('min_max_scale', MinMaxScaler()),('agglomerative_clustering',AgglomerativeClustering(n_clusters=3, linkage='ward'))])\n",
    "c2 = pipe.fit(mirna_r)[-1]\n",
    "\n",
    "#rna\n",
    "#rna->Standardscaler->PCA->Kmeans\n",
    "pipe = Pipeline([('standard_scaler', StandardScaler()),('pca', PCA(0.9)),('kmeans_clustering',KMeans(n_clusters=3, max_iter=500,random_state=SEED))])\n",
    "c3 = pipe.fit(rna_new)[-1]\n",
    "#rna->Bonferroni->MaxminScaler->Kmeans\n",
    "pipe = Pipeline([('min_max_scale', MinMaxScaler()),('kmeans_clustering',KMeans(n_clusters=3, max_iter=500,random_state=SEED))])\n",
    "c4 = pipe.fit(rna_r)[-1]\n",
    "\n",
    "#illumina\n",
    "#Bonferroni->PCA->Spectral cluestering\n",
    "pipe = Pipeline([('pca', PCA(0.9)),('spectral_clustering',SpectralClustering(n_clusters=3, assign_labels='discretize'))])\n",
    "c5 = pipe.fit(illu_r)[-1]\n",
    "#Bonferroni->PCA->Agglomerative\n",
    "pipe = Pipeline([('pca', PCA(0.9)),('agglomerative_clustering',AgglomerativeClustering(n_clusters=3, linkage='ward'))])\n",
    "c6 = pipe.fit(illu_r)[-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = compute_vector_indicator(c1,c2,c3,c4,c5,c6)\n",
    "\n",
    "\n",
    "# setting distance_threshold=0 ensures we compute the full tree.\n",
    "\n",
    "model = AgglomerativeClustering(n_clusters=3)\n",
    "model = model.fit(X)\n",
    "\n",
    "print(\"silhuette: \", silhouette_score(X, model.labels_))\n",
    "print(\"rand indexa: \", adjusted_rand_score(label, model.labels_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.labels_\n",
    "df_clinical_case = ExtractClinicalCase(cases_id).get_df_clinical_case()\n",
    "\n",
    "df_clinical_case.sort_values(by='case_id', inplace=True)\n",
    "df = pd.DataFrame()\n",
    "df['case_id'] = cases_id\n",
    "df['label'] = y_pred\n",
    "clinica_cases_id = [el.replace('\\n', '') for el in df_clinical_case['case_id']]\n",
    "\n",
    "label = df.loc[df['case_id'].isin(clinica_cases_id)]['label']\n",
    "df_clinical_case['label'] = label\n",
    "\n",
    "plot_clinical_data(df_clinical_case, 'prior_malignancy', 'Prior Malignancy Distribution')\n",
    "plot_clinical_data(df_clinical_case, 'age_at_diagnosis', 'Age at diagnosis Distribution')\n",
    "plot_clinical_data(df_clinical_case, 'tumor_stage', 'Tumor stage Distribution')\n",
    "plot_clinical_data(df_clinical_case, 'morphology', 'Morphology Distribution')\n",
    "plot_clinical_data(df_clinical_case, 'cigarettes_per_day', 'Cigarettes per day Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
