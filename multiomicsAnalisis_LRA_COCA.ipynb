{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-omics analisis with LRA cluster and COCA\n",
    "\n",
    "* [Load data and preprocessing](#Load-data-and-preprocessing)\n",
    "* [Dataset alignment](#Dataset-alignment)\n",
    "* [LRA cluster](#LRA-cluster)\n",
    "    * [LRA cluster R implementation](#LRA-cluster-R-implementation)\n",
    "    * [LRA cluster python implementation](#LRA-cluster-python-implementation)\n",
    "* [Clinic Data](#Clinic-Data)\n",
    "* [COCA](#COCA)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import r\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from myclass.CleanMergeDataset import Clean_Merge_Dataset\n",
    "from myclass.BonferroniTtest import Bonferroni_Ttest\n",
    "#import plotly.express as px\n",
    "from sklearn.cluster import DBSCAN, KMeans, AgglomerativeClustering, SpectralClustering\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#reload(myclass.BonferroniTtest)\n",
    "#reload(myclass.CleanMergeDataset)\n",
    "from rpy2.robjects.packages import STAP\n",
    "import rpy2.robjects as robjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and preprocessing\n",
    "\n",
    "Loading the datasets, clean them through class *Clean_Merge_Dataset*, reduce the number of features with *Bonferroni_Ttest*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_normal: (305, 60486)\n",
      "Data_tumor: (1071, 60486)\n",
      "All data: (1376, 60486)\n",
      "{'TCGA-LUAD', 'TCGA-LUSC'}\n",
      "Features completly 0 values 2227 removed\n",
      "Features completely Nan 0 removed\n",
      "Final dataset shape (959, 58258)\n",
      "Data_normal: (136, 1884)\n",
      "Data_tumor: (623, 1884)\n",
      "All data: (759, 1884)\n",
      "{'TCGA-LUAD', 'TCGA-LUSC'}\n",
      "Features completly 0 values 287 removed\n",
      "Features completely Nan 0 removed\n",
      "Final dataset shape (558, 1596)\n",
      "Data_normal: (125, 25981)\n",
      "Data_tumor: (1082, 25981)\n",
      "All data: (1207, 25981)\n",
      "{'TCGA-LUAD', 'TCGA-LUSC'}\n",
      "Features completly 0 values 0 removed\n",
      "Features completely Nan 2597 removed\n",
      "Final dataset shape (1206, 19697)\n",
      "Final dataset shape: (959, 12963)\n",
      "Final dataset shape: (558, 235)\n",
      "Final dataset shape: (1206, 15698)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "if os.path.exists('./SimilarityNetworkFusion/data-ready/final_dataset_common.json') is False:\n",
    "\n",
    "    data_normal = pd.read_pickle('./SimilarityNetworkFusion/data-ready/RNA_dataframe_normal').replace('/', '\\\\')\n",
    "    data_tumor = pd.read_pickle('./SimilarityNetworkFusion/data-ready/RNA_dataframe').replace('/', '\\\\')\n",
    "    dataset_RNA, y_RNA, cases_id_RNA = Clean_Merge_Dataset(name='RNA').transform(data_normal, data_tumor)\n",
    "    df_RNA = pd.concat([dataset_RNA, cases_id_RNA], axis=1)\n",
    "\n",
    "    data_normal = pd.read_pickle('./SimilarityNetworkFusion/data-ready/miRNA_dataframe_normal').replace('/', '\\\\')\n",
    "    data_tumor = pd.read_pickle('./SimilarityNetworkFusion/data-ready/miRNA_dataframe').replace('/', '\\\\')\n",
    "    dataset_miRNA, y_miRNA, cases_id_miRNA= Clean_Merge_Dataset(name='miRNA').transform(data_normal, data_tumor)\n",
    "    df_miRNA = pd.concat([dataset_miRNA, cases_id_miRNA], axis=1)\n",
    "\n",
    "    data_normal = pd.read_pickle('./SimilarityNetworkFusion/data-ready/illumina-27-450-normal').replace('/', '\\\\')\n",
    "    data_tumor = pd.read_pickle('./SimilarityNetworkFusion/data-ready/illumina450-27-tumor').replace('/', '\\\\')\n",
    "    dataset_illumina, y_illumina, cases_id_illumina= Clean_Merge_Dataset(name='illumina').transform(data_normal, data_tumor)\n",
    "    df_illumina = pd.concat([dataset_illumina, cases_id_illumina], axis=1)\n",
    "\n",
    "    dataset_RNA = Bonferroni_Ttest(label_case_id_into_X=True, alpha=0.05).fit_transform(pd.concat([df_RNA, y_RNA], axis=1), y_RNA)\n",
    "    dataset_miRNA = Bonferroni_Ttest(label_case_id_into_X=True, alpha=0.05).fit_transform(pd.concat([df_miRNA, y_miRNA], axis=1), y_miRNA)\n",
    "    dataset_illumina = Bonferroni_Ttest(label_case_id_into_X=True, alpha=0.05).fit_transform(pd.concat([df_illumina, y_illumina], axis=1), y_illumina)\n",
    "\n",
    "    df_illumina = pd.concat([df_illumina,y_illumina], axis=1)\n",
    "    df_miRNA = pd.concat([df_miRNA,y_miRNA], axis=1)\n",
    "    df_RNA = pd.concat([df_RNA,y_RNA], axis=1)\n",
    "   \n",
    "    \n",
    "\n",
    "    \n",
    "    dataset_illumina.to_pickle('./SimilarityNetworkFusion/data-ready/illumina_pickle.pkl')\n",
    "    dataset_RNA.to_pickle('./SimilarityNetworkFusion/data-ready/rna_pickle.pkl')\n",
    "    dataset_miRNA.to_pickle('./SimilarityNetworkFusion/data-ready/miRNA_pickle.pkl')\n",
    "    df_illumina.to_pickle('./SimilarityNetworkFusion/data-ready/illumina_pickle_No_B.pkl')\n",
    "    df_RNA.to_pickle('./SimilarityNetworkFusion/data-ready/rna_pickle_No_B.pkl')\n",
    "    df_miRNA.to_pickle('./SimilarityNetworkFusion/data-ready/miRNA_pickle_NoB.pkl')\n",
    "   \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "else:\n",
    "    dataset_illumina.read_pickle('./SimilarityNetworkFusion/data-ready/illumina_pickle.pkl')\n",
    "    dataset_RNA.read_pickle('./SimilarityNetworkFusion/data-ready/rna_pickle.pkl')\n",
    "    dataset_miRNA.read_pickle('./SimilarityNetworkFusion/data-ready/miRNA_pickle.pkl')\n",
    "    df_illumina.read_pickle('./SimilarityNetworkFusion/data-ready/illumina_pickle_No_B.pkl')\n",
    "    df_RNA.read_pickle('./SimilarityNetworkFusion/data-ready/rna_pickle_No_B.pkl')\n",
    "    df_miRNA.read_pickle('./SimilarityNetworkFusion/data-ready/miRNA_pickle_NoB.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "(430, 15700)\n",
      "(430, 12965)\n",
      "(430, 237)\n"
     ]
    }
   ],
   "source": [
    "def uniqueCaseID(data):\n",
    "  \n",
    "    new = {}\n",
    "    new[\"case_id1\"] = []\n",
    "    data = data.sort_values(by=['case_id']).reset_index(drop=True)\n",
    "    for i,row in data.iterrows():\n",
    "        new[\"case_id1\"].append(data.loc[i,\"case_id\"]+\"_\"+str(data.loc[i,'label']))\n",
    "    \n",
    "    new_df = pd.DataFrame(new, columns = [\"case_id1\"])\n",
    "    conc_df = pd.concat([new_df,data], axis=1)\n",
    "    conc_df = conc_df.drop([\"case_id\"], axis=1)\n",
    "    \n",
    "    return conc_df\n",
    "\n",
    "\n",
    "\n",
    "illu = uniqueCaseID(dataset_illumina)\n",
    "rna = uniqueCaseID(dataset_RNA)\n",
    "mirna = uniqueCaseID(dataset_miRNA)\n",
    "\n",
    "print(illu.isnull().sum().sum())\n",
    "print(rna.isnull().sum().sum())\n",
    "print(mirna.isnull().sum().sum())\n",
    "\n",
    "\n",
    "\n",
    "i1 = set(illu['case_id1'])\n",
    "i2 = set(mirna['case_id1'])\n",
    "i3 = set(rna['case_id1'])\n",
    "\n",
    "#Prendiamo i case_id_label che stanno in tutti e 3 le omiche\n",
    "distinct_case_id = [x for x in i2 if x in i1 and x in i3]\n",
    "\n",
    "\n",
    "#print(distinct_case_id)\n",
    "#Filtriamo i case_id_label che non stanno in tutte e 3 le omiche\n",
    "illu = illu.loc[illu['case_id1'].isin(distinct_case_id)]\n",
    "rna = rna.loc[rna['case_id1'].isin(distinct_case_id)]\n",
    "mirna = mirna.loc[mirna['case_id1'].isin(distinct_case_id)]\n",
    "\n",
    "illu = illu.sort_values(by=['case_id1']).reset_index(drop=True)\n",
    "rna = rna.sort_values(by=['case_id1']).reset_index(drop=True)\n",
    "mirna = mirna.sort_values(by=['case_id1']).reset_index(drop=True)\n",
    "\n",
    "#print(rna)\n",
    "#print(mirna)\n",
    "#print(illu)\n",
    "\n",
    "print(illu.shape)\n",
    "print(rna.shape)\n",
    "print(mirna.shape)\n",
    "\n",
    "\n",
    "label = illu['label']\n",
    "label[label == False] ='False'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRA cluster\n",
    "\n",
    "In the following two sections we analyze the LRA cluster algorithm, an example of early multi-omics integration. We have re-implemented this algorithm in python, trying to improve its efficiency by eliminating some superfluous operations or re-implementing them using more efficient python libraries such as jax.LRA clsuter extract features that can be usefull for a clustering algorithm.We tested it with the **Agglomerative clustering, Spectral clustering and KMeans algorithms**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRA cluster R implementation\n",
    "\n",
    "In this section we run the official R implementation of LRA cluster.We run the R code by using the rpy2 library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "  r_illu_d = ro.conversion.py2rpy(illu.drop([\"case_id1\",\"label\"], axis=1))\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "  r_miRNA_d = ro.conversion.py2rpy(mirna.drop([\"case_id1\",\"label\"], axis=1))\n",
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "  r_rna_d = ro.conversion.py2rpy(rna.drop([\"case_id1\",\"label\"], axis=1))\n",
    "\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import SignatureTranslatedAnonymousPackage\n",
    "\n",
    "\n",
    "##LRA cluster R\n",
    "file_LRA_cluster = open(\"LRAcluster/R/LRAcluster.R\",'r')\n",
    "\n",
    "string_LRA_cluster = ''.join(file_LRA_cluster.readlines())\n",
    "\n",
    "LRA_cluster = SignatureTranslatedAnonymousPackage(string_LRA_cluster, \"LRAcluster\")\n",
    "\n",
    "#Trasformiamo in matrici i 3 dataset\n",
    "matrix_r_miRNA_d = LRA_cluster.getMatrix(r_miRNA_d)\n",
    "matrix_r_illu_d = LRA_cluster.getMatrix(r_illu_d)\n",
    "matrix_r_rna_d = LRA_cluster.getMatrix(r_rna_d)\n",
    "\n",
    "#Uniamo le matrici --> data\n",
    "import time;\n",
    "\n",
    "unionMatrix = LRA_cluster.unionMatrix3(matrix_r_illu_d, matrix_r_rna_d, matrix_r_miRNA_d)\n",
    "start_time = time.time()\n",
    "output_R = LRA_cluster.LRAcluster(unionMatrix,3)\n",
    "print(start_time - time.time())\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "    output = ro.conversion.rpy2py(output_R[0])\n",
    "\n",
    "clustering = KMeans(n_clusters=3, max_iter=500).fit(output)\n",
    "clustering1 = AgglomerativeClustering(n_clusters=3, linkage='ward').fit(output)\n",
    "clustering2 = SpectralClustering(n_clusters=3, assign_labels='discretize').fit(output)\n",
    "\n",
    "\n",
    "print(\"KMEANS\")\n",
    "print(\"silhuette: \", silhouette_score(output, clustering.labels_))\n",
    "print(\"rand indexa: \", adjusted_rand_score(label, clustering.labels_))\n",
    "print(\"AGGLOMERATIVE CLUSTERING\")\n",
    "print(\"silhuette: \", silhouette_score(output, clustering1.labels_))\n",
    "print(\"rand indexa: \", adjusted_rand_score(label, clustering1.labels_))\n",
    "print(\"SPECTRAL CLUSTERING\")\n",
    "print(\"silhuette: \", silhouette_score(output, clustering2.labels_))\n",
    "print(\"rand indexa: \", adjusted_rand_score(label, clustering2.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRA cluster python implementation\n",
    "\n",
    "In this section we perform our python implementation of the LRA cluster algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "-23.108436107635498\n",
      "KMEANS\n",
      "silhuette:  0.60462165\n",
      "rand indexa:  0.5709097682152928\n",
      "AGGLOMERATIVE CLUSTERING\n",
      "silhuette:  0.5469721\n",
      "rand indexa:  0.6277861134873446\n",
      "SPECTRAL CLUSTERING\n",
      "silhuette:  0.47729582\n",
      "rand indexa:  0.7411932170705463\n"
     ]
    }
   ],
   "source": [
    "#LRA cluster python implementation\n",
    "label = illu['label']\n",
    "label[label == False] ='False'\n",
    "\n",
    "from PyLRAcluster.LRACluster import LRAcluster\n",
    "import time\n",
    "\n",
    "\n",
    "illu_m = np.transpose(illu.drop([\"case_id1\",\"label\"], axis=1).to_numpy())\n",
    "rna_m = np.transpose(rna.drop([\"case_id1\",\"label\"], axis=1).to_numpy())\n",
    "mirna_m = np.transpose(mirna.drop([\"case_id1\",\"label\"], axis=1).to_numpy())\n",
    "\n",
    "start_time = time.time()\n",
    "output,p = LRAcluster([illu_m,rna_m,mirna_m],['gaussian','poisson','poisson'],3)\n",
    "print(start_time - time.time())\n",
    "\n",
    "clustering = KMeans(n_clusters=3, max_iter=500).fit(output)\n",
    "clustering1 = AgglomerativeClustering(n_clusters=3, linkage='ward').fit(output)\n",
    "clustering2 = SpectralClustering(n_clusters=3, assign_labels='discretize').fit(output)\n",
    "\n",
    "\n",
    "print(\"KMEANS\")\n",
    "print(\"silhuette: \", silhouette_score(output, clustering.labels_))\n",
    "print(\"rand indexa: \", adjusted_rand_score(label, clustering.labels_))\n",
    "print(\"AGGLOMERATIVE CLUSTERING\")\n",
    "print(\"silhuette: \", silhouette_score(output, clustering1.labels_))\n",
    "print(\"rand indexa: \", adjusted_rand_score(label, clustering1.labels_))\n",
    "print(\"SPECTRAL CLUSTERING\")\n",
    "print(\"silhuette: \", silhouette_score(output, clustering2.labels_))\n",
    "print(\"rand indexa: \", adjusted_rand_score(label, clustering2.labels_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot graph##\n",
    "le = LabelEncoder()\n",
    "labels_num = le.fit_transform(clustering2.labels_)\n",
    "plt.figure('LRA 3 dimension Spectral clustering', figsize=(15,15))\n",
    "ax = plt.axes(projection = '3d')\n",
    "ax.legend()\n",
    "ax.scatter(output[:,0],output[:,1],output[:,2],c=labels_num);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinic Data\n",
    "\n",
    "We want to apply the information retrieved from clinical-data to the results obtained by the best clustering  (Spectral clustering). The link between the datas is the case_id. The fields chosen from clinical-data's file are:\n",
    "- tumor_stage: stage of tumor.\n",
    "- prior_malignancy: precedent diagnosys of tumors.\n",
    "- age_at_diagnosis: patient's age which is diagnosed the tumor. We have considered only the year's decades.\n",
    "- morphology: kind of tumor, which is identified from a code id.\n",
    "- cigarettes per day: the average number of cigarettes smoked by the patient in one day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATI CLINICI\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\"\"\"\n",
    "    Class to extract the clinical_case from the json file.\n",
    "    It returns a dataframe in the following form:\n",
    "    case_id| ...[clinical case]...| label.\n",
    "\"\"\"\n",
    "#set the cluster predicted labels as the labels predicted by Spectral clustering\n",
    "y_pred = clustering2.labels_\n",
    "\n",
    "#Class used to extract clinical data from the json file.\n",
    "class ExtractClinicalCase:\n",
    "    def __init__(self, cases_id):\n",
    "        with open('./SimilarityNetworkFusion/clinical.cases_selection.2020-11-12.json', 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "\n",
    "        remove_el = list()\n",
    "        for el in data:\n",
    "            if el['case_id'] not in cases_id:\n",
    "                remove_el.append(el)\n",
    "\n",
    "        for el in remove_el:\n",
    "            data.remove(el)\n",
    "        \n",
    "        clinical_data = {'case_id': '',\n",
    "                        'tumor_stage': '',\n",
    "                        'prior_malignancy': '',\n",
    "                        'age_at_diagnosis': None,\n",
    "                        'morphology': '',\n",
    "                        'label': ''}\n",
    "\n",
    "        self.df = pd.DataFrame(data=[], columns=clinical_data.keys())\n",
    "\n",
    "        for i, el in enumerate(data):\n",
    "            clinical_data['case_id'] = el['case_id']\n",
    "            clinical_data['tumor_stage'] = el['diagnoses'][0]['tumor_stage']\n",
    "            clinical_data['prior_malignancy'] = el['diagnoses'][0]['prior_malignancy']\n",
    "            if el['diagnoses'][0]['age_at_diagnosis'] is not None:\n",
    "                value = int(el['diagnoses'][0]['age_at_diagnosis'])/365\n",
    "                clinical_data['age_at_diagnosis'] = self.__truncate__(value)\n",
    "\n",
    "            clinical_data['morphology'] = el['diagnoses'][0]['morphology']\n",
    "            if el['exposures'][0]['cigarettes_per_day'] is not None:\n",
    "                value = int(el['exposures'][0]['cigarettes_per_day'])\n",
    "                clinical_data['cigarettes_per_day'] = value\n",
    "\n",
    "            self.df = self.df.append(pd.DataFrame(clinical_data, index=[i]), ignore_index=True)\n",
    "        \n",
    "    def get_df_clinical_case(self):\n",
    "        return self.df\n",
    "\n",
    "    def __truncate__(self, n, decimals=-1):\n",
    "        \"\"\"\n",
    "            Function to take the decade of the age.\n",
    "        \"\"\"\n",
    "        multiplier = 10 ** decimals\n",
    "        return int(n * multiplier) / multiplier\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "cases_id = [el.split('_')[0] for el in rna['case_id1']]\n",
    "df_clinical_case = ExtractClinicalCase(cases_id).get_df_clinical_case()\n",
    "\n",
    "df_clinical_case.sort_values(by='case_id', inplace=True)\n",
    "df = pd.DataFrame()\n",
    "df['case_id'] = cases_id\n",
    "df['label'] = y_pred\n",
    "clinica_cases_id = [el.replace('\\n', '') for el in df_clinical_case['case_id']]\n",
    "\n",
    "label = df.loc[df['case_id'].isin(clinica_cases_id)]['label']\n",
    "df_clinical_case['label'] = label\n",
    "\n",
    "\n",
    "#Function to plot clinical data \n",
    "def plot_clinical_data(df_clinical_case, name_clinical_field, title=''):\n",
    "    dict_ = {}\n",
    "    df = pd.DataFrame()\n",
    "    df_clinical_case.dropna(inplace=True)\n",
    "\n",
    "\n",
    "    for l in range(0, 3):\n",
    "        dict_['Cluster'] = l\n",
    "        for el in set(df_clinical_case[name_clinical_field]):\n",
    "            el_cluster = df_clinical_case[df_clinical_case['label'] == l]\n",
    "            count = el_cluster[el_cluster[name_clinical_field] == el]['case_id'].count()\n",
    "            dict_[el] = count\n",
    "\n",
    "        df = df.append(pd.DataFrame(dict_, index=[0]))\n",
    "\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for key in df.columns[1:]:\n",
    "        fig = fig.add_trace(\n",
    "            go.Bar(name=key, x=df['Cluster'], y=df[key])\n",
    "        )\n",
    "    \n",
    "    # Change the bar mode\n",
    "    fig.update_layout(barmode='stack',\n",
    "                      title=title,\n",
    "                      xaxis_title=\"Clusters\",\n",
    "                      yaxis_title=\"Count\")\n",
    "    fig.show() \n",
    "    return\n",
    "\n",
    " \n",
    "plot_clinical_data(df_clinical_case, 'prior_malignancy', 'Prior Malignancy Distribution')\n",
    "plot_clinical_data(df_clinical_case, 'age_at_diagnosis', 'Age at diagnosis Distribution')\n",
    "plot_clinical_data(df_clinical_case, 'tumor_stage', 'Tumor stage Distribution')\n",
    "plot_clinical_data(df_clinical_case, 'morphology', 'Morphology Distribution')\n",
    "plot_clinical_data(df_clinical_case, 'cigarettes_per_day', 'Cigarettes per day Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCA \n",
    "\n",
    "In this section we have implemented the cluster of clusters algorithm (COCA). This algorithm was performed on the best combinations of preprocessing and algorithms that emerged from the single omic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-14-3a329d0b0809>\u001b[0m(26)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     24 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     25 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 26 \u001b[0;31m\u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m\u001b[0millu_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniqueCaseID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_illumina\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m\u001b[0mmirna_new\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0muniqueCaseID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_miRNA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> df_illumina\n",
      "      cg27269921  cg26372517  cg06226384  cg27650434  cg09793866  cg20025656  \\\n",
      "0       0.145436    0.491993    0.238829    0.061273    0.574314    0.179827   \n",
      "1       0.023482    0.029641    0.127048    0.018317    0.411468    0.599194   \n",
      "2       0.022901    0.397441    0.124989    0.039252    0.904835    0.407803   \n",
      "3       0.152088    0.340465    0.204440    0.055004    0.585254    0.334862   \n",
      "4       0.177851    0.440205    0.179807    0.044693    0.548487    0.257736   \n",
      "...          ...         ...         ...         ...         ...         ...   \n",
      "1202    0.017499    0.255105    0.669827    0.135481    0.387898    0.271086   \n",
      "1203    0.017904    0.178790    0.611193    0.118348    0.427151    0.260033   \n",
      "1204    0.042831    0.301041    0.581110    0.157899    0.431813    0.254627   \n",
      "1205    0.012004    0.229627    0.651501    0.103842    0.464790    0.230744   \n",
      "1206    0.013766    0.234139    0.641877    0.128164    0.520419    0.241259   \n",
      "\n",
      "      cg00324733  cg15591678  cg14694952  cg10319505  ...  cg10246296  \\\n",
      "0       0.019343    0.015581    0.012865    0.092136  ...    0.080620   \n",
      "1       0.017732    0.107776    0.013740    0.014585  ...    0.029765   \n",
      "2       0.016394    0.018574    0.012854    0.021118  ...    0.053243   \n",
      "3       0.014521    0.233927    0.016145    0.091733  ...    0.154017   \n",
      "4       0.014981    0.012817    0.017158    0.073228  ...    0.049702   \n",
      "...          ...         ...         ...         ...  ...         ...   \n",
      "1202    0.076943    0.098406    0.049654    0.024014  ...    0.070938   \n",
      "1203    0.086563    0.083462    0.039982    0.030254  ...    0.056422   \n",
      "1204    0.089232    0.115358    0.051076    0.072675  ...    0.100975   \n",
      "1205    0.031534    0.046106    0.022862    0.016819  ...    0.034803   \n",
      "1206    0.036830    0.043796    0.019636    0.018319  ...    0.118965   \n",
      "\n",
      "      cg23661676  cg04228553  cg14234680  cg06840042  cg03005055  cg01427567  \\\n",
      "0       0.497102    0.012065    0.010047    0.010551    0.025099    0.234456   \n",
      "1       0.590133    0.008278    0.006162    0.012283    0.016623    0.150736   \n",
      "2       0.671824    0.009300    0.006980    0.012820    0.031282    0.207062   \n",
      "3       0.459527    0.008094    0.007547    0.012393    0.023479    0.239422   \n",
      "4       0.289850    0.009491    0.006965    0.010071    0.024540    0.177258   \n",
      "...          ...         ...         ...         ...         ...         ...   \n",
      "1202    0.423662    0.090283    0.082943    0.122799    0.080137    0.178873   \n",
      "1203    0.484449    0.087114    0.067111    0.131664    0.072625    0.282625   \n",
      "1204    0.476724    0.142083    0.129485    0.227555    0.102816    0.269005   \n",
      "1205    0.404699    0.066242    0.038519    0.087281    0.032023    0.196455   \n",
      "1206    0.453748    0.038844    0.044248    0.078535    0.034731    0.182531   \n",
      "\n",
      "      cg25932713                               case_id      label  \n",
      "0       0.891458  f3501466-cf32-4866-b5fb-e94dd32341bc  TCGA-LUAD  \n",
      "1       0.948731  1b354837-4925-4480-ac32-6b44d0957314  TCGA-LUAD  \n",
      "2       0.945953  762dea8a-5b41-4058-979a-b7876ed13d7e  TCGA-LUAD  \n",
      "3       0.935065  b61abdfd-b7a0-4e1a-b570-d1eaecad3a9e  TCGA-LUAD  \n",
      "4       0.852377  d2c1e896-6886-4122-bb48-5fbcd3f641f4  TCGA-LUAD  \n",
      "...          ...                                   ...        ...  \n",
      "1202    0.741643  8994c8c4-9ea0-46cb-b4a5-0055d7da5bfa      False  \n",
      "1203    0.852068  27fceec1-3298-4cdd-a4e6-8f5cf34604f0      False  \n",
      "1204    0.846186  7a0ea814-f0de-4bc4-a81a-daa000559369      False  \n",
      "1205    0.919566  e28cbc9a-aa60-4bfb-8d89-8c33ee97f560      False  \n",
      "1206    0.871864  be5dcf02-8097-4a97-af32-6a9b02c079d3      False  \n",
      "\n",
      "[1206 rows x 19697 columns]\n",
      "ipdb> c\n",
      "silhuette:  0.3640247697745836\n",
      "rand indexa:  0.5577603562160004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Clustering a singola omica\n",
    "def vectorIndicator(indicator_vector_matrix,labels):\n",
    "    new_encodings = []\n",
    "    for i in range(labels.shape[0]):\n",
    "        label_encoding = [0,0,0]\n",
    "        label_encoding[labels[i]] = 1 # 0 -> [1,0,0] 1 ->[0,1,0] 2->[0,0,1]\n",
    "        new_encodings.append(label_encoding)\n",
    "    if indicator_vector_matrix.shape[0] == 0:\n",
    "        indicator_vector_matrix = np.array(new_encodings)\n",
    "    else:\n",
    "        indicator_vector_matrix = np.concatenate((indicator_vector_matrix,np.array(new_encodings)),axis=1)\n",
    "    return indicator_vector_matrix\n",
    "\n",
    "def compute_vector_indicator(*args):\n",
    "    indicator_vector_matrix = np.array([])\n",
    "    for a in args:\n",
    "        indicator_vector_matrix = vectorIndicator(indicator_vector_matrix,a.labels_)\n",
    "    return indicator_vector_matrix\n",
    "\n",
    "\n",
    "import pdb;pdb.set_trace()\n",
    "illu_new = uniqueCaseID(df_illumina)\n",
    "mirna_new =uniqueCaseID(df_miRNA)\n",
    "rna_new = uniqueCaseID(df_RNA)\n",
    "\n",
    "i1 = set(illu_new['case_id1'])\n",
    "i2 = set(mirna_new['case_id1'])\n",
    "i3 = set(rna_new['case_id1'])\n",
    "\n",
    "#Prendiamo i case_id_label che stanno in tutti e 3 le omiche\n",
    "distinct_case_id = [x for x in i2 if x in i1 and x in i3]\n",
    "\n",
    "\n",
    "#print(distinct_case_id)\n",
    "#Filtriamo i case_id_label che non stanno in tutte e 3 le omiche\n",
    "illu_new = illu_new.loc[illu_new['case_id1'].isin(distinct_case_id)]\n",
    "rna_new = rna_new.loc[rna_new['case_id1'].isin(distinct_case_id)]\n",
    "mirna_new = mirna_new.loc[mirna_new['case_id1'].isin(distinct_case_id)]\n",
    "\n",
    "illu_new = illu_new.sort_values(by=['case_id1']).reset_index(drop=True)\n",
    "rna_new = rna_new.sort_values(by=['case_id1']).reset_index(drop=True)\n",
    "mirna_new = mirna_new.sort_values(by=['case_id1']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "label = illu_new['label']\n",
    "label[label == False] = 'False'\n",
    "\n",
    "#No bonferroni\n",
    "illu_new = illu_new.drop(['case_id1','label'],axis=1)\n",
    "mirna_new = mirna_new.drop(['case_id1','label'],axis=1)\n",
    "rna_new = rna_new.drop(['case_id1','label'],axis=1)\n",
    "\n",
    "#With bonferroni\n",
    "illu_r = illu.drop(['case_id1','label'],axis=1)\n",
    "mirna_r = mirna.drop(['case_id1','label'],axis=1)\n",
    "rna_r = rna.drop(['case_id1','label'],axis=1)\n",
    "\n",
    "SEED = 9\n",
    "#mirna->Bonferroni->Maxminscaler->PCA->Spectral cluestering\n",
    "pipe = Pipeline([('min_max_scale', MinMaxScaler()),('pca', PCA(0.9)),('spectral_clustering',SpectralClustering(n_clusters=3, assign_labels='discretize'))])\n",
    "c1 = pipe.fit(mirna_r)[-1]\n",
    "#mirna->Bonferroni->Maxminscaler->PCA->Spectral cluestering\n",
    "pipe = Pipeline([('min_max_scale', MinMaxScaler()),('agglomerative_clustering',AgglomerativeClustering(n_clusters=3, linkage='ward'))])\n",
    "c2 = pipe.fit(mirna_r)[-1]\n",
    "\n",
    "#rna\n",
    "#rna->Standardscaler->PCA->Kmeans\n",
    "pipe = Pipeline([('standard_scaler', StandardScaler()),('pca', PCA(0.9)),('kmeans_clustering',KMeans(n_clusters=3, max_iter=500,random_state=SEED))])\n",
    "c3 = pipe.fit(rna_new)[-1]\n",
    "#rna->Bonferroni->MaxminScaler->Kmeans\n",
    "pipe = Pipeline([('min_max_scale', MinMaxScaler()),('kmeans_clustering',KMeans(n_clusters=3, max_iter=500,random_state=SEED))])\n",
    "c4 = pipe.fit(rna_r)[-1]\n",
    "\n",
    "#illumina\n",
    "#Bonferroni->PCA->Spectral cluestering\n",
    "pipe = Pipeline([('pca', PCA(0.9)),('spectral_clustering',SpectralClustering(n_clusters=3, assign_labels='discretize'))])\n",
    "c5 = pipe.fit(illu_r)[-1]\n",
    "#Bonferroni->PCA->Agglomerative\n",
    "pipe = Pipeline([('pca', PCA(0.9)),('agglomerative_clustering',AgglomerativeClustering(n_clusters=3, linkage='ward'))])\n",
    "c6 = pipe.fit(illu_r)[-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = compute_vector_indicator(c1,c2,c3,c4,c5,c6)\n",
    "\n",
    "\n",
    "# setting distance_threshold=0 ensures we compute the full tree.\n",
    "\n",
    "model = AgglomerativeClustering(n_clusters=3)\n",
    "model = model.fit(X)\n",
    "\n",
    "print(\"silhuette: \", silhouette_score(X, model.labels_))\n",
    "print(\"rand indexa: \", adjusted_rand_score(label, model.labels_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.labels_\n",
    "df_clinical_case = ExtractClinicalCase(cases_id).get_df_clinical_case()\n",
    "\n",
    "df_clinical_case.sort_values(by='case_id', inplace=True)\n",
    "df = pd.DataFrame()\n",
    "df['case_id'] = cases_id\n",
    "df['label'] = y_pred\n",
    "clinica_cases_id = [el.replace('\\n', '') for el in df_clinical_case['case_id']]\n",
    "\n",
    "label = df.loc[df['case_id'].isin(clinica_cases_id)]['label']\n",
    "df_clinical_case['label'] = label\n",
    "\n",
    "plot_clinical_data(df_clinical_case, 'prior_malignancy', 'Prior Malignancy Distribution')\n",
    "plot_clinical_data(df_clinical_case, 'age_at_diagnosis', 'Age at diagnosis Distribution')\n",
    "plot_clinical_data(df_clinical_case, 'tumor_stage', 'Tumor stage Distribution')\n",
    "plot_clinical_data(df_clinical_case, 'morphology', 'Morphology Distribution')\n",
    "plot_clinical_data(df_clinical_case, 'cigarettes_per_day', 'Cigarettes per day Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
